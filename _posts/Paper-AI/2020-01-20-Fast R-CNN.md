---
layout: post
title: Object Detection [2] Fast R-CNN
excerpt: AI Paper Review_Fast R-CNN
comments: true
categories : [AI Paper Review, Fast R-CNN]
use_math: true
---

### 1. R-CNN의 문제점
 
R-CNN은 2014년 SOTA를 주름잡는 Detection 모델이었고, 딥러닝 알고리즘(ConvNet)을 적용했다는 점에서 상당한 주목을 받았었습니다. 하지만 Selective Search를 통해 2000개의 Region Proposals을 찾은 후 각각의 Region으로부터 CNN을 수행했기 때문에 연산비용이 상당했었습니다. Detection은 빠르게 객체를 검출해내야만 하는데, 이를 적용하기에는 다소 무리가 있었습니다.

그 후 R-CNN이 나온지 1년 후 **Fast R-CNN[^0]**이 발표되었습니다. Fast R-CNN은 Selective Search와 CNN의 순서를 바꿈으로써 연산량을 획기적으로 줄였다는것이 핵심입니다. 

<p align="center">
<img width="600" src="https://www.dropbox.com/s/ftgao2h2zueu527/fast-RCNN.png?raw=1">
</p>


### 2. Fast R-CNN

Fast R-CNN은 다음의 순서로 진행이 됩니다.

1. Selective Search를 시행하여 Region Proposal의 Bounding Box 좌표값을 특정합니다.
2. 이미지를 CNN(VGG16)에 통과시켜 Feature Map을 추출합니다(각각의 Region을 CNN에 통과시키는것이 아님).
3. Selective Search로 부터 획득한 Bounding Box의 좌표값으로 이미지의 위치를 특정하고 ROI Pooling을 수행합니다.
4. Pooling의 결과로 얻는 Feature는 FC Layer를 통과하여 Classification과 Bounding Box Regression을 진행합니다.

Selective Search와 CNN의 순서를 바뀌었다면서 **왜 첫번째 순서가 Selective Search가 나오는가**에 대한 이유는 다음과 같습니다. CNN을 통해 나온 Feature Map은 이미지가 아니기 때문에 Region Proposal을 얻을 수 없습니다. 따라서 Selective Search를 먼저 수행하여 Region Proposal의 Bounding Box만 획득하는것입니다(즉, 좌표값만 획득). 그 이후에 CNN을 수행하여 나온 Feature Map에서 Bounding Box를 찍어주어 이미지가 아닌 Feature Map에서도 Region Proposal을 특정할 수 있게 되는 것입니다.

여기서 문제가 발생합니다. R-CNN에서는 각각의 Region Proposal들을 Crop하고 Warpping을 하기 때문에 최종 형태가 이미지가 됩니다. 그래서 CNN의 입력으로 넣을 수 있었던 것입니다. 하지만 Fast R-CNN에서는 이미지를 먼저 CNN에 입력으로 넣기 때문에 이미지가 아닌 Feature Map의 Region Proposal을 Resize할 방법이 없었습니다. 그래서 나온 개념이 RoI(Region of Interest) Pooling 입니다.

### 3. RoI Pooling

<p align="center">
<img width="400" src="https://www.dropbox.com/s/dnwwo7monmagyug/fastrcnn3.png?raw=1">
</p>

위 이미지를 보면 CNN을 통해 나온 Feature Map들의 여러 Region Proposal의 크기가 각각 다르다는것을 알 수 있습니다. RoI Pooling을 통해 다양한 크기의 Region Proposal이 일정한 크기로 변형시켜준다는 것입니다.

RoI는 (r,c,h,w)의 좌표 형태로 표현됩니다. (r,c)는 좌상단의 꼭지점 좌표이고 (h,w)는 높이와 너비입니다. 고정된 크기 (H,W)의 Feature Map으로 변환하고자 한다면, $\frac{h}{H} \times \frac{w}{W}$ 의 Grid를 만들어준 후 Max-Pooling을 하면 (H,W)의 크기를 가지는 Feature Map으로 변환이 되게 됩니다.

##### Example

아래와 같은 상황을 고려해봅니다. 어떠한 크기의 Input 이미지가 있다고 해봅시다. 해당 이미지는 Conv Layer들을 거쳐서 아래와 같이 8x8 크기의 Feature Map이 되었습니다.

<p align="center">
<img width="400" src="https://www.dropbox.com/s/m4p7hc56ifin3dm/1.jpg?raw=1">
</p>

해당 이미지에서 RoI를 찾아서 하나의 좌표를 얻습니다. (x,y,h,w)=(0,3,5,7)이 되는 어떠한 RoI입니다.

<p align="center">
<img width="400" src="https://www.dropbox.com/s/w6r7ukodske9s60/2.jpg?raw=1">
</p>

이 RoI를 RoI Pooling Layer를 거쳐 2x2의 고정된 크기의 Feature Map을 만들고 싶습니다. 따라서 $\frac{5}{2} \times \frac{7}{2} = 2 \times 3$의 Grid를 만들어 보줍니다. 여기서 정수가 나오지 않고 소수점이 나오면, 반올림 또는 버림을 하여 Stride를 조정해주면 됩니다. Stride는 Grid의 크기와 항상 똑같이 이동합니다.

<p align="center">
<img width="400" src="https://www.dropbox.com/s/f38y2k5or05isqx/3.jpg?raw=1">
</p>

각각의 Cell에서 Max Pooling을 시행해주면 최종적으로 아래와 같은 고정된 크기의 Feature Map을 구할 수 있습니다.

<p align="center">
<img src="https://www.dropbox.com/s/ede98ayr1ddkeee/output.jpg?raw=1">
</p>

### 4. Multi-task loss

RoI Pooling을 통과한 동일한 크기의 Feature Map들은 똑같은 형태로 두개의 output layer를 생성하여 Classification과 bbox regression에 사용됩니다.

classification을 하기 위해서 activation function으로 softmax를 사용하여 K+1개의 class를 예측하게 됩니다. 손실함수는 $L_{cls}(p, u) = -log(p_{u})$ 가 됩니다. $p$는 확률이고 $u$는 정답 클래스의 인덱스를 나타냅니다. 즉, $p_{u}$는 정답 클래스일 확률입니다.

bbox regression은 R-CNN에서 구한것과 동일한 방법으로 각 좌표를 예측하게 되고 손실함수만 달라집니다.

$$
    L_{loc}(t^{u},v)=\sum_{i\in{x,y,w,h}}(smooth_{L1}(t_{i}^{u}-v_{i}))
$$

$$
    smooth_{L1}(x) = \begin{cases}0.5x^2\qquad if \quad|x| < 1\\|x| - 0.5 \qquad otherwise\end{cases}
$$

$t_{i}^{u} - v_{i}$는 GT의 좌표와 RP의 좌표의 차이임으로 오차에 해당하며, 이 오차가 크다는것은 Outlier일 확률이 높다는 말로 해석할 수 있습니다. 즉, 가중치가 잘못 Fitting 될 수 있다는 것이지요. smmoth함수는 오차가 $\pm1$ 안쪽에 있다면 제곱의 형태를 손실함수로 사용하며, 그렇지 않을 경우에는 1차함수를 손실함수로 사용함으로써 Outlier에 보다 강건하게(Robust) 되는것 입니다.

이제 두개의 Loss를 아래와 같이 합칩니다.

$$
    L(p, u, t^{u}, v) = L_{cls}(p,u) + \lambda[u\geq1]L_{loc}(t^{u},v)
$$

여기에서 $\lambda[u\geq1]$을 살펴보자면, $\lambda$는 두 Loss를 합치면서 발생하는 불균형을 조절하는 상수입니다. 논문에서는 1을 사용하였습니다. $u$는 정답 클래스의 인덱스가 1보다 클때는(not Background) 1이 되고, 0일때는 (Backgound) 0이 되게 됩니다. 이것을 **Iverson bracket indicator function**이라고 지칭합니다.

이렇게 두개의 Loss를 합쳐 Multi-Loss를 생성함으로써 R-CNN에서는 두번에 걸쳐 계산하는것을 한번에 계산이 가능하게 되었습니다.

### 5. Result

논문의 결과는 상당했습니다. R-CNN에 비해서 속도는 학습시간은 9배 정도 향상되었으며 추론시간은 무려 213배 향상되었습니다. mAP 또한 기존 66%에서 70% 까지 상승되었습니다.

<p align="center">
<img width="400" src="https://www.dropbox.com/s/xp08uxa3w6mtcfx/result.PNG?raw=1">
</p>

 속도향상의 원인은 세가지 입니다. 첫번째는 Selective Search와 CNN의 순서를 바꿈으로써 연산량을 획기적으로 줄였다는것, 두번째는 역전파를 이용하여 학습이 가능해졌다는것, 세번째는 SVD(Sigular Vector Decomposition)입니다. SVD의 개념을 간단히 설명하자면 행렬을 분해하여 곱을 합의 형태로 바꾸는것입니다. 이 개념을 FC Layer의 가중치를 계산할때 적용하여 연산량을 상당히 줄일 수 있었다고 합니다.

### 6. Conclusion

Fast R-CNN은 R-CNN에서의 문제점을 획기적으로 수정하면서 보다 개선된 end-to-end를 실현하였습니다. 하지만 Selective Search는 여전히 연산량이 방대하고 Network에 포함되어있지 않는 독립적인 모델이기 때문에 진정한 end-to-end는 아니었습니다. 저자도 이러한 문제를 알고있었는지 몇달 후 개선된 모델을 선보이게 됩니다.

#### Reference

[^0]: https://arxiv.org/pdf/1504.08083.pdf