---
layout: post
title: Object Detection [4] YoLo v1
excerpt: AI Paper Review_YoLo
comments: true
categories : [AI Paper Review, YoLo, You only Look once]
use_math: true
---

YoLo는 하나의 단일 네트워크로 구성되어 있습니다. R-CNN 계열의 알고리즘과 달리 탐지영역(Bounding Box)와 분류(Classification)을 한번에 처리하기 때문에 매우 빠른 속도를 보여주고 있습니다. 이처럼 한번에 보고 처리한다 라는 의미에서 You Only Look Once(YoLo)라는 이름을 부여했다고 합니다.

YoLo에 대한 내용은 [deepsystem]("https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p")에서 제공한 자료가 잘 되어있기에 해당 글을 참고하여 작성하였습니다.

### 1. Process

우선 이미지를 SxS grid로 나누고, 각 grid cell에서 Bounding Box좌표와 1개의 confidence scores를 예측합니다. confidence scores는 해당 Bounding Box가 물체를 포함하고 있는지, class를 잘 예측하고 있는지에 대한 신뢰성을 나타내는 지표 입니다. 이 지표를 구하는 산식은 아래와 같습니다.

$$
    Confidence = Pr(Object) \ast IOU^{truth}_{pred}
$$

만약 물체가 grid cell에 존재하지 않으면 confidence는 0이 될것이고, 예측을 잘 했다면 IOU가 1에 가까워  지고 Confidence도 1에 가까운 값을 기대할 수 있습니다.

Bounding Box는 (x, y, w, h, confidence) 5개의 값으로 구성되어있습니다. (x, y, w, h)는 Bounding Box의 중심과 가로,세로를 나타냅니다.

각 grid cell은 $Pr(Class_{i}\vert Object)$ 인 조건부 확률로서 class를 예측하게 됩니다. 그리고 아래의 산식에의해서 class scores를 계산하게 됩니다.

$$
    class\; scores = Pr(Class_{i} \vert Object) \ast Pr(Object) \ast IOU^{truth}_{pred}
$$

즉, class scores는 grid cell 안에 물체가 존재할 때의 특정 클래스일 확률에 confidence를 곱하여 구하게 됩니다. 해당 scores가 의미하는것은 class가 Bounding Box에 나타날 확률과 예측된 Bounding Box가 물체를 얼마나 잘 적합하고 있는지를 모두 나타내주는 지표로 활용됩니다.

### 2. Network Design

먼저 Input 이미지를 448x448 size로 변경합니다. 그리고 20개의 Conv Layer를 가진 GoogleLeNet를 사용하고 추가적으로 4개의 Conv Layer와 2개의 FC Layer를 붙여줍니다. 마지막 FC Layer에서 나온 Output Feature는 다시 7x7x30의 형태로 변경해줍니다. 해당 논문에서는 각 grid cell마다 2개의 Bounding Box를 예측했습니다. 따라서 Feature Map에서 7x7의 grid에 5개의 Bounding Box값과 20개의 class로 구성된 데이터셋(PASCAL VOC)을 사용했기때문에, S=7, B=2, C=20이 되어 7x7x(2*5+20)이 되게 되는것입니다.

<p align="center">
<img width="600" alt="train" src="https://www.dropbox.com/s/k0amwnwzcjm499g/train.PNG?raw=1">
</p>

7x7x30 형태의 Feature Map은 아래와 같이 해석할 수 있습니다.

<p align="center">
<img width="600" alt="train_1" src="https://www.dropbox.com/s/875pqnj7xrpqa3z/train_1.PNG?raw=1">
</p>

좌측 하단의 물체(강아지)의 중심 Cell을 빨간색으로 표시했을때, 해당 cell은 물체를 탐지해야할 책임을 부여받습니다. 해당 cell은 2개의 Bounding Box를 예측하게 됩니다.

30개의 채널에서 1~5까지의 Index는 각각의 (x, y, w, h, c) 값을 가지게 됩니다. (x, y) 좌표는 각 grid cell의 크기를 기준으로 0~1 사이의 값으로 정규화 됩니다. 마찬가지로 (w, h)의 값은 전체 이미지의 (w, h)를 기준으로 정규화 됩니다.

<p align="center">
<img width="600" alt="train_2" src="https://www.dropbox.com/s/tbiayx80zvkmmpm/train_2.PNG?raw=1">
</p>

 해당 논문은 class의 수가 20개인 PASCAL VOC 데이터셋을 사용하였습니다. Bounding Box가 나타내는 10개의 값을 제외한 나머지 20개 채널의 값은 $ pr(Class_{i}\vert Object)$ 를 나타냅니다.

### 3. Loss Function

YoLo는 각 grid cell당 B개의 Bounding Box를 예측하게 되는데, 그중 Ground Truth와 IOU가 가장 높은 한개의 Box만 선택합니다. Loss Function은 총 3개의 Part로 구성되어있습니다.

#### Localization

$$
    \lambda_{coord}\sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{obj}\left[(x_{i} - \hat{x_{i}})^{2} + (y_{i} - \hat{y_{i}})^{2} \right] + \lambda_{coord}\sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{obj}\left[(\sqrt{w_{i}} - \sqrt{\hat{w_{i}}})^{2} + (\sqrt{h_{i}} - \sqrt{\hat{h_{i}}})^{2} \right]
$$

이미지에는 물체가 포함된 Box보다 그렇지 않는 Box(즉, Background)가 더 많기 때문에 Error를 계산할때 불균형이 일어날 수 있습니다. 따라서 물체가 포함된 영역의 grid cell에는 $\lambda_{coord} = 5$를, 그렇지 않은 영역에는 $\lambda_{noobj} = 0.5$를 곱하여 이를 해결하였습니다. 

$\mathbb{1}_{i,j}^{obj}$은 i번째 grid cell에서 j번째 Bounding Box에 물체가 존재할경우를 나타내며 만약 존재한다면 1, 그렇지 않으면 0으로 표현합니다. 이전에 살펴보았듯이 Bounding Box는 물체의 중심이 존재하는 grid cell에서만 탐지를 할 책임이 부여되므로 그렇지 않은 grid cell에서의 Loacalization Loss는 0이 됩니다.

#### confidence

$$
    \sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{obj} \left(C_{i} - \hat{C_{i}}\right)^{2} + \lambda_{noobj}\sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{noobj}\left(C_{i} - \hat{C_{i}}\right)^{2}
$$

$\hat{C_{i}}$는 Confidence 즉, $Pr(Object) \ast IOU^{truth}_{pred}$를 나타냅니다
Localization과 마찬가지로 i번째 grid cell에서 j번째 Bounding Box에 물체가 존재할때, 앞쪽의 Loss만 살아남고 뒤쪽은 0이 됩니다. 반대로 물체가 존재하지 않으면 앞쪽의 Loss는 0이되고 뒤쪽의 Loss만 살아남게 됩니다.

#### classification

$$
    \sum_{i}^{S^{2}}\mathbb{1}_{i,j}^{obj}\sum_{c \in classes} (p_{i}(c) - \hat{p_{i}}(c))^{2}
$$

$\hat{p_{i}}(c)$는 grid cell에 물체가 존재할때, class c가 들어있을 확률, 즉 $P(class_{i}\vert object)$ 입니다. Localization, confiden와 마찬가지로 i번째 grid cell에서 j번째 Bounding Box에 물체가 존재할때, classification loss를 계산하며, 그렇지 않을때는 0이 됩니다.

#### multi-part loss function

$$
    \lambda_{coord}\sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{obj}\left[(x_{i} - \hat{x_{i}})^{2} + (y_{i} - \hat{y_{i}})^{2} \right] + \lambda_{coord}\sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{obj}\left[(\sqrt{w_{i}} - \sqrt{\hat{w_{i}}})^{2} + (\sqrt{h_{i}} - \sqrt{\hat{h_{i}}})^{2} \right] + \\

    \sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{obj} \left(C_{i} - \hat{C_{i}}\right)^{2} + \lambda_{noobj}\sum_{i}^{S^{2}}\sum_{j=0}^{B}\mathbb{1}_{i,j}^{noobj}\left(C_{i} - \hat{C_{i}}\right)^{2} + \\

    \sum_{i}^{S^{2}}\mathbb{1}_{i,j}^{obj}\sum_{c \in classes} (p_{i}(c) - \hat{p_{i}}(c))^{2}
$$

자세히 살펴보면 grid cell에 물체가 존재하지 않는 영역은 패널티 Parameter $\lambda$를 사용하여 에러를 최소화 하거나 0을 만들어 버리도록 구성되어있습니다. 이제 위에서 살펴본 모든 Loss를 더해주어 최종 loss function을 만들었습니다.

### 4. Inference

추론을 하는 방법은 다음과 같이 진행됩니다. 우선 한장의 이미지로부터 class scores을 구해주어야 합니다.

<p align="center">
<img width="600" alt="train_3" src="https://www.dropbox.com/s/yne4f5t0jx8x47h/train_3.PNG?raw=1">
<img width="600" alt="train_4" src="https://www.dropbox.com/s/m0fntljhtdqkqu1/train_4.PNG?raw=1">
</p>

class scores를 구하기 위해 조건부확률과 confidence를 곱해줍니다. 현재 B=2 이기 때문에 각 cell마다 2개의 class scores를 구할 수 있습니다.

<p align="center">
<img width="600" alt="train_6" src="https://www.dropbox.com/s/hqqw91mypc4y7c2/train_6.PNG?raw=1">
<img width="600" alt="train_7" src="https://www.dropbox.com/s/811ny7yogjfye66/train_7.PNG?raw=1">
</p>

이것을 모든 cell에 대하여 수행해주면 총 7x7x2=98개의 predict box와 class scores를 구하게 됩니다. 이렇게 구한 class scores는 각각 NMS를 통해 정렬 및 0으로 처리가 되고, 가장 높은 class scores를 가진 predict box만 뽑으면 모든 추론이 완료되게 됩니다.

### 5. 한계점

YoLo는 각 grid cell마다 2개의 predict box밖에 가지지 못하고, 단 한가지의 class만을 가집니다. 그렇기 때문에 물체가 너무 작아 하나의 grid cell에 여러개가 겹치는 경우에는 제대로 탐지를 하지 못한다는 단점이 있습니다.

<p align="center">
<img width="400" alt="flocks of birds" src="https://www.dropbox.com/s/eo2uaxrdm6t9bsz/birds.PNG?raw=1">
</p>
<center>작은 새떼들은 찾지 못한다</center>

### 6. Result

<p align="center">
<img width="400" alt="results1" src="https://www.dropbox.com/s/1gc38p8heon7l5h/results2.PNG?raw=1">
</p>

PASCAL VOC 2007과 2012 데이터셋을 합쳐서 학습시킨 결과, YoLo는 63.4% mAP 45FPS를 보여주었습니다. Two Stage method인 Faster R-CNN이 mAP 73.2%와 7FPS 라는 수치와 비교해보았을때, 정확도는 조금 떨어졌지만 6배가 넘는 FPS 수치를 보여주며 실시간 탐지의 지평을 열게 되었습니다.

### 7. Conclusion

YoLo는 탐지영역과 분류영역을 통합한 모델로써, 45FPS의 실시간에 가까운 추론을 해내며 정확도 또한 일정 수준 이상 보장해주는 아주 훌륭한 One Stage mothod입니다. 하지만 작은 객체는 잘 탐지해내지 못한다는점과, grid cell을 분리할때 7등분을 한다는점은, mAP의 측면에서 좋지 못한 결과를 보여주었습니다. 연구자들은 이러한 단점을 하나씩 보완해나가기 시작하였고 YoLo v2가 등장하게 되었습니다.