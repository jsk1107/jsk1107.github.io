---
layout: post
title: Object Detection [5] SSD:Single Shot MultiBox Detector
excerpt: AI Paper Review_SSD
comments: true
categories : [AI Paper Review, SSD, Single Shot MultiBox Detector]
use_math: true
---


YoLo v1이 등장한 이후 약 5달뒤 Single Show Multibox Detector라는 논문이 등장하였다. 해당 논문은 당시 YoLo v1보다 빠르고 Faster R-CNN보다 더 정확한 Detector로 SOTA모델이었다. 

최근에는 데이터 적합도의 퍼포먼스 등을 간단히 알아보기위해 사용하며, 임베디드 시스템에서 주로 이용되는 모델이다. 

성능이 타 모델 대비 부족하지 않으면서도 빠른 속도를 보여주는점은 우수한 모델이라고 생각한다. 

### Concept

SSD의 Main Idea는 Multi Scale Feature Map을 획득하는것이다. 향후 중요한 CNN 아키텍처중 하나인 FPN의 조상님 격 되는 내용이라고 볼 수 있다.

또 하나의 중요한 특징으로는 Default Box가 있다. 이는 Faster R-CNN에서 등장한 Anchor Box와 유사한 개념이다.

이제 꼼꼼히 두가지 특징들에 대해서 살펴보도록 하자.

#### CNN Architecture

<p align="center">
<img width="600" alt="network" src="https://www.dropbox.com/s/vdluj4p8b4kuht7/network.PNG?raw=1">
</p>

SSD의 네트워크 구조는 VGG16을 차용한다. 맨 마지막에 있는 FC layer를 제외한 네트워크 구조를 가져온다. 첫번째 Block에서는 conv5-3영역의 Feature Map을 선택하고, 나머지는 pooling을 거쳐 나온 Feature Map을 선택한다.

각각의 Feature Map으로부터 3x3 size를 가진 6개의 Conv Layer를 통해 Bounding Box와 Classification을 진행한다. 과거 Detection 모델에서는 맨 마지막 Feature Map에서만 진행했다면, SSD에서는 6개의 Feature Map에서 진행한다는 차이점이 있다.

왜 이런방법을 사용하는 것일까??

CNN Layer와 Pooling을 거치게 되면 Feature Map의 가로,세로의 크기는 점점 작아진다는것은 이미 알고있을 것이다. 바꿔 말하자면 이것은 Grid cell이 점점 커지는것을 의미한다. 이러한 현상을 통해 한가지 인사이트를 발견할 수 있다.

아래 그림을 살펴보자.

<p align="center">
<img width="600" alt="network" src="https://www.dropbox.com/s/6ww4caohhe4cn2x/feature_map.PNG?raw=1">
</p>

8x8 size의 Feature Map에서는 Default Box의 크기가 작은것을 알 수 있다. 반면 4x4 size의 Feature Map에서는 크기가 크다. Default Box가 아직 무엇인지는 몰라도, 그림에서 빨간색, 파란색 Box의 크기를 보면 변하지 않았다는것을 알 수있다(대략 가로:1.2, 세로:2.5)

직관적으로 유추해보자면, 파란색 Box는 작은 고양이를 탐지해낼 수 있지만, 큰 강아지는 탐지해내기 어려워보인다. 반면에 빨간색 Box는 큰 강아지는 탐지해낼 수 있지만, 작은 고양이는 탐지해내기 어려워보인다. 

이러한 이유때문에 여러개의 Feature Map을 획득한뒤 추론을 진행하여 그 결과를 합친다면 보다 좋은 성능을 보일 수 있다는것이다.

물론 논문에서 사용한 VGG16이 아닌 ResNet 등 다른 모델로도 좋은 결과를 낼 수 있다고 저자는 말한다. 타 모델 사용시 FC layer가 존재한다면 해당 부분은 제외한 네트워크 구조를 사용하면 되기 때문이다.

#### Default Box

SSD는 Faster R-CNN에서 사용하는 Anchor Box와 비슷한 개념인 Default Box를 사용합니다. 고정된 Box라는 의미로 한번 설정해놓은 Default Box는 불변적이며, 각각의 Feature Map의 수만큼 Default Box를 준비해놓습니다. 좀더 구체적으로 살펴보면:

#### scale

$$
    s_{k} = s_{min} + \frac{s_{max} - s_{min}}{m - 1}(k - 1), \qquad k \in [1,m]\\
$$

$$
    s_{min}=0.2, \quad s_{max}=0.9, \quad m= the\;number\;feature\;maps 
$$

$k$는 Feature Map의 갯수가 $m$개일때의 $k$번째라는것을 나타내는 인덱스 입니다.
$s_{min}\; s_{max}$은 가장 첫번째로 나타나는 Feature Map의 Default Box의 scale은 0.2이고 가장 마지막에 나타나는 Feature Map의 Default Box의 scale은 0.9라는 것입니다. 그리고 사이에 있는 Feature Map들의 Default Box의 scale은 등간격 크기로 설정합니다. 

#### aspect ratio

Default Box마다 각기 다른 aspect ration를 설정해주어야 합니다. 이 부분은 고정값으로 사용합니다.

$$
    a_{r} \in \{ 1, 2, 3, \frac{1}{2}, \frac{1}{3} \}
$$

그리고 aspect ration가 1인 Default Box에 $s^{\prime}_{k} = \sqrt{s_{k}s_{k+1}}$ 크기만큼 확대한 Default Box를 하나 더 추가해서 총 6개의 Box를 생성합니다.

#### width & height

위에서 구한 scale과 aspect ration를 활용하여 값을 계산해줍니다.

$$
    w_{k}^{a} = s_{k}\sqrt{a_{r}}, \quad h_{k}^{a} = \frac{s_{k}}{\sqrt{a_{r}}}
$$

#### center

Default Box의 중심은 Feature Map의 크기로 정규화된 값을 사용합니다.

$$
    (x, y) = (\frac{i+0.5}{\vert f_{k} \vert}, \frac{j+0.5}{\vert f_{k} \vert})
$$

$$
    \vert f_{k} \vert = size\;of\;the\;k-th\;square\;feature\;map \quad i,j \in [0, \vert f_{k} \vert )
$$

이렇게 Feature Map당 6개의 Default Box를 생성하였습니다. 이제 Box를 각각의 위치(grid cell)마다 두고 Ground Truth Box와 매칭하는 작업을 진행합니다.

### 3. Loss Function

SSD의 Loss Function은 Faster R-CNN과 유사한 형태로 구성되어있습니다. 사실 One Stage의 Loss Function은 거의 비슷한 편입니다.

$$
    L(x,c,l,g) = \frac{1}{N}(L_{conf}(x,c) + \alpha L_{loc}(x,l,g))
$$

$N$은 매칭된 Default Box의 갯수입니다. 만약 하나도 매칭된것이 없다면 Loss는 0이 됩니다. $\alpha$는 1로 설정하였다고 합니다.
#### localization loss

localization loss는 여전히 Smooth L1 loss를 사용하고 있습니다. 개념은 Faster R-CNN과 유사한 방식으로 계산됩니다.

$$
    L_{loc}(x,l,g)=\sum_{i \in Pos}^{N} \sum_{m \in \{ cx, cy, w, h \}} x_{ij}^{k}smooth_{L1}(l_{i}^{m} - \hat{g_{j}}^{m})
$$

$$
    \hat{g_{j}}^{cx} = (g_{j}^{cx}-d_{i}^{cx})/d_{i}^{w} \quad \hat{g_{j}}^{cy} = (g_{j}^{cy}-d_{i}^{cy})/d_{i}^{h}\\
    \hat{g_{j}}^{w} = log(\frac{g_{j}^{w}}{d_{i}^{w}}) \quad \hat{g_{j}}^{h} = log(\frac{g_{j}^{h}}{d_{i}^{h}})
$$

Ground Truth Box와 미리 계산해둔 Default Box와 계산하여 $\hat{g_{j}}^{m}$를 획득하고 이를 Predict Box와 계산하여 localizaation loss를 구하게 됩니다.

#### classification loss

마찬가지로 multiple class confidence를 구하기 위해서 softmax loss를 사용해줍니다.

$$
    L_{conf}(x,c) = - \sum_{i \in Pos}^{N}x_{ij}^{p}log(\hat{c_i}^{p}) - \sum_{i \in Neg}log(\hat{c_{i}}^{0}) \qquad where \quad \hat{c_{i}}^{p} = \frac{exp(c_{i}^{p})}{\sum_{p}exp(c_{i}^{p})}
$$

$x_{ij}^{p}$는 p라는 class의 i번째 Default Box와 j번째 Ground Truth Box가 매칭 되었을때는 1, 그렇지 않을땐 0을 나타내는 지시함수 입니다.

#### Hard negative mining

고질적인 문제에 봉착했습니다. 각 grid cell마다 물체의 유무를 검사하기 때문에 배경의 수가 압도적으로 많기 때문입니다. 이것을 해결하기위해 각각의 Default Box에 대해서 confidence loss를 정렬하고 negative(배경)와 positive(물체)의 비율을 3:1이 되도록 뽑습니다. 이러한 방법으로 최적화를 빠르게 수행하고 학습도 안정적으로 진행했다고 설명하고 있습니다.

### 4. Result

SSD의 결과는 단연코 SOTA였습니다. two-stage method인 Faster R-CNN과 비교해보아도 mAP, FPS 모두 앞도했습니다. input size를 300x300으로 했을때대비 512x512로 했을때는 mAP는 무려 81.6%를 보여주었습니다. 이것은 input size를 키웠을 때, 작은 물체를 더욱 잘 탐지 한다는것을 보여주는 결과라고 할 수 있습니다.

<p align="center">
<img alt="result" src="https://www.dropbox.com/s/fsc33p75f924j1v/Result.PNG?raw=1">
</p>

이러한 결과는 PASCAL VOC2007 데이터셋 뿐만아니라 VOC2012, COCO데이터셋에서도 우수한 결과를 보여주었습니다.

### 5. Conclusion

SSD는 MultiBox Detector라는 개념을 도입하여 정확도와 속도 두가지를 모두잡은 해자모델임에는 틀림없습니다. 또한 각각의 Feature Map마다 Prediction을 한다는 컨셉은 이후 Feature Pyramid Network(FPN)에 영감을 주게됩니다. 현재에도 SSD는 종종 사용하는 모델이기 때문에, 조금 어렵더라도 완벽하게 알고 넘어가야 향후 나오는 모델을 이해하는데 어려움이 없을것입니다.