---
layout: post
title: Segmentation [2] U-Net
excerpt: AI Paper Review_U-Net
comments: true
categories : [AI Paper Review, U-Net]
use_math: true
---

Biomedical 분야에서 Segmentaion은 중요한 분야라고 합니다. 세포를 분할하여 데이터를 처리해야하는데, 우선 이미지에서 세포를 분할하는 과정이 여간 쉽지 않았던 모양입니다.

U-Net은 이러한 문제를 해결하기 위해 등장한 알고리즘입니다. 기본적인 내용은 FCN을 계승하고있으며, 데이터 전처리 방법과 독특한 방법으로 Augmentaion을 진행하여 성능을 높인 모델입니다.

Segmentation 분야에서는 FCN과 더불어 시조새격인 알고리즘이지만, 현재까지도 많은 분야에서 사용되고 있습니다.

### 1. Network Architecture

U-Net은 수축하는 경로인 Contracting Path 부분과 확대하는 경로인 Expansive Path 부분이 있습니다. 어려운 용어인듯 하지만 Conv Layer을 거쳐가면서 DownSampling이 되는부분과 Up-Conv Layer를 거쳐가면서 UpSampling 되는 과정입니다.

<p align="center">
<img width="400" alt="figure1" src="https://www.dropbox.com/s/y2zv7hn3c3l1bes/figure1.PNG?raw=1">
</p>

입력 이미지의 크기를 572x572x1(흑백) 라고 한다면, 2개의 3x3 Conv Layer와 ReLU, 1개의 2x2 max pooling을 거쳐줍니다.

이때 Conv Layer는 Padding처리를 하지 않아 이미지 size가 2씩 감소하게되며 max pooling은 Stride를 2로 설정함으로써 크기는 2배로 축소(DownSample)하고 채널은 2배로 늘려줍니다. 

수축과정을 5번 반복하여 마지막으로 28x28x1024의 Feature Map을 획득하게되면 이제부터 확장과정을 시작하게 됩니다.

확장은 2x2 convolution layer를 활용하여 Upsampling을 진행합니다. 수축과정의 마지막 Feature Map의 크기를 2배 확장시키고, 채널은 2배 줄이면 56x56x512의 Feature Map을 얻을 수 있습니다.

FCN논문에서 살펴보았듯이 단순히 upsampling을 하는것은 좋지 못한 결과를 낸다는것을 알았습니다. 이것을 보완하기위해 U-Net에서도 Skip-Connection과 같은 아이디어를 사용합니다.

그림에서 회색 화살표를 살표보면, 수축과정에서 얻은 Feature Map과, 확장과정에서 얻은 Feature Map을 연결(Concat)한다는것을 알 수 있습니다. FCN은 Feature Map의 정보를 Sum 하는 반면, U-Net에선 연결을 하기 때문에 채널이 다시 2배가 됩니다.

이 과정을 반복하여 확장과정의 마지막부분에서는 1x1 conv layer를 붙여서 class의 갯수만큼의 채널로 만들어주면 U-Net이 완성됩니다.

### 2. Overlap tile

U-Net은 Biomedical 분야에서 시작이 된 모델입니다. 바이오 관련 데이터는 질병을 다루기 때문에 데이터를 획득하기도 매우 어렵고, 이미지 자체고 엄청난 초고화질입니다.

딥러닝을 위해서는 보다 많은 학습 데이터를 확보해야만 했고, GPU를 여러장 묶어서 사용하는것이 아니라면 OOM(Out Of Memory)가 발생할 가능성이 매우 높았습니다. 이러한 문제를 해결해야할 필요가 있었지요.

<p align="center">
<img width="500" alt="figure2" src="https://www.dropbox.com/s/zzkzmkn8ll407mn/figure2.PNG?raw=1">
</p>


그래서 생각하게된 아이디어가 Overlap tile입니다. 위 그림에서 노란색 영역의 바깥라인을 보면 안쪽에 있는 패턴이 거울에 반사된것처럼 확장된것을 볼 수 있습니다.

우선 이미지를 위처럼 미러링을 해준 후 파란색 영역만큼의 크기로 이미지를 잘라줍니다(Patch). 학습으로 사용되는 이미지는 전체 이미지가 아닌 Patch된 이미지가 입력으로 들어가게됩니다. 그리고 실제 Prediction되는 영역은 미러링된 바깥영역은 제외가되고 노란색 영역만 segmentation이 되는 구조입니다.

이 방법을 활용하면 미러링되는 영역의 크기와, Patch의 크기에 따라서 부족한 데이터를 얼마든지 확보할 수 있다는 장점이 있으며, 이미지를 분할하여 입력하기 때문에 OOM 문제도 제거할 수 있습니다.

또한, 영역의 가장자리부분에 대해서는 Pixel Prediction이 보다 잘 되는 장점도 있습니다.

### 3. Training

U-Net 모델로부터 얻은 최종 Feature Map에 Pixel-wise Softmax 활성함수를 붙여줍니다. Loss Function은 Cross Entropy를 사용합니다.

$$
    E=\sum_{x\in \Omega}w(x)log(p_{l(x)}(x))
$$

 여기에서 $w(x)$는 Ground Truth Pixel이 아니라 Weight Map을 통해 구한 약간 변형된 값입니다. 각각의 세포들간의 가장 짧은 거리와 두번째로 짧은 거리를 구해서 경계라인에 대한 가중치를 반영한 $w(x)$를 사용하게 됩니다. 
 
 $$
    w(x)=w_{c}(x) + w_{0}exp \left(-\frac{(d_{1}(x) + d_{2}(x)))^{2}}{2\sigma^{2}}\right)\\
    w_{c} : weight \; map \\
    d_{1}(x) : distance \; to \;the \;border \;of \;the \;nearest \;cell \\
    d_{2}(x) : distance \; to \;the \;border \;of \;the \; second \;nearest \;cell
$$ 

논문에서는 $w_{0}=10, \sigma \approx 5$를 이용한것이 가장 성능이 좋았다고 합니다. 이와같은짓을 하는 이유는 각각의 class간 경계라인을 보다 확실하게 구분할 수 있도록 학습을 하기 위함입니다. 

<p align="center">
<img width="500" alt="figure3" src="https://www.dropbox.com/s/rxub69ncovy8daz/weight_map.png?raw=1">
</p>
<center>좌 : Ground Truth Mask, 우 : weight map이라고 합니다</center>


이유는 모르겠지만, 우리가 기존에 많이 사용하고 있는 PASCAL VOC 데이터나 COCO 데이터 등에도 mask 이미지를 보면 모두 경계라인이 다른 색으로 구분되어있습니다. 

또한 경계라인의 색은 Ingnore_label 처리되어 loss 계산에서 제거한다는 점이 weigth map의 아이디어와 유사하다고 생각합니다.

### 4. Result

U-net팀은 별다른 전처리, 후처리를 사용하지 않고서도 EM segmentation challenge에서 SOTA를 달성했습니다. ISBI cell tracking chaalenge 2015에서도 상당히 높은 IOU를 보여주며 segmentation의 SOTA를 달성했습니다.

### 5. Conclusion

바이오 메디컬 분야와 같이 데이터의 수가 적으면서 높은 정확도를 요구하는 영역에서 U-Net은 매우 효과적인 알고리즘임에 틀림없습니다. 이러한 특성 때문인지 U-Net은 제조영역에서도 많이 사용되고 있으며, 2019년 SOCAR에서도 차량 파손 검출 프로젝트에 해당 모델을 사용할정도로 뛰어난 성능을 보여준 갓모델이라고 할 수 있습니다.